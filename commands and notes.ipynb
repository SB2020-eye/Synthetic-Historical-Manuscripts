{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating-Synthetic-Handwritten-Historical-Documents (repo cloned from https: // github.com/DIVA-DIA/Generating-Synthetic-Handwritten-Historical-Documents)\n",
    "\n",
    "# Conda environment: gendocs                  # (Note: using pip to install, not conda)\n",
    "    # conda create -n gendocs python=3.6      # (in Anaconda Prompt)\n",
    "\n",
    "# Requirements (in Anaconda Prompt)\n",
    "    # pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117\n",
    "    # pip install opencv-python --no-use-pep517\n",
    "    # pip install ipython traitlets jupyter psutil setuptools ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor matplotlib scikit-image wandb pytorch_ssim fast-ctc-decode editdistance prettytable\n",
    "    # needed?\n",
    "        # pip install jupyter-core\n",
    "        # pip install -q --upgrade ipython\n",
    "        # pip install -q --upgrade ipykernel\n",
    "    # pip install config\n",
    "\n",
    "# Setup (in Git Bash)\n",
    "    # cd ..\n",
    "    # cd ..\n",
    "    # cd Desktop/ManuscriptProject/Code\n",
    "    # git clone https://github.com/DIVA-DIA/Generating-Synthetic-Handwritten-Historical-Documents.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd C:/Users/scott/Desktop/ManuscriptProject/Code/Generating-Synthetic-Handwritten-Historical-Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE DOMAIN GENERATION (if needed for changing latex to pdf and/or pdf to png images)\n",
    "\n",
    "# Latex to pdf (colab)\n",
    "    # %cd Source_Domain_Generation\n",
    "    # ! sudo apt-get install texlive\n",
    "    # ! sudo apt install texinfo\n",
    "    # ! sudo apt-get install texlive-fonts-recommended\n",
    "    # ! sudo apt-get install texlive-fonts-extra\n",
    "    # ! sudo apt-get install texlive-latex-extra\n",
    "    # ! sudo apt install texlive-full\n",
    "    # ! pdflatex generate_book.tex\n",
    "# pdf to png images (colab)\n",
    "    # !pip install PyMuPDF\n",
    "    # make sure pdf file is in Source_Domain_Generation folder\n",
    "    # put pdf file name in PDFTextPositionsToCsv.py\n",
    "        # this line: doc = fitz.open('{full path of file ending in .pdf}')\n",
    "    # %cd ..\n",
    "    # %rm -r source_domain-csv/\n",
    "    # %rm -r source_domain/\n",
    "    # !python PDFTextPositionsToCsv.py\n",
    "# pdf to png images (local)\n",
    "    # pip install PyMuPDF\n",
    "    # put pdf file in Source_Domain_Generation folder\n",
    "    # put pdf file name in PDFTextPositionsToCsv.py\n",
    "# this line: doc = fitz.open('{full path of file ending in .pdf}')\n",
    "    # python Source_Domain_Generation/PDFTextPositionsToCsv.py\n",
    "\n",
    "# From Manuel:\n",
    "    # \"The trick here is first to execute the latex script, which generates one huge PDF, and then execute the PDFTextPositionsToCsv.py, \n",
    "    # which is going to create a lot of small .png out of every page together with the word and character positions. You just have to put \n",
    "    # the generated information into the HTR_ctc/data/generated/train/A folder. If memory serves me right the target data, so your historical \n",
    "    # texts have to go into folder B and the csv data has to be saved and put into A as well.\"\n",
    "    # NOTE from SB: I believe Manuel is mistaken about where the generated information goes. Follow instructions below.\n",
    "\n",
    "# Move generated information as follows:\n",
    "    # png images -> PyTorch-CycleGAN/datasets/{model name}/train/A\n",
    "    # csv files -> PyTorch-CycleGAN/datasets/{model name}/train/A-csv\n",
    "    # 10% of png images -> PyTorch-CycleGAN/datasets/{model name}/test/A\n",
    "        # NOTE: I'm not sure if the corresponding csv files should be moved or deleted or left alone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (colab only)\n",
    "    # import sys\n",
    "    # sys.path.insert(0, 'C:/Users/scott/Desktop/ManuscriptProject/Code/Generating-Synthetic-Handwritten-Historical-Documents')\n",
    "    # sys.path.insert(1, 'C:/Users/scott/Desktop/ManuscriptProject/Code/Generating-Synthetic-Handwritten-Historical-Documents/HTR_ctc')\n",
    "    # sys.path.insert(2, 'C:/Users/scott/Desktop/ManuscriptProject/Code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN')\n",
    "    # sys.path.insert(3, 'C:/Users/scott/Desktop/ManuscriptProject/Code/Generating-Synthetic-Handwritten-Historical-Documents/HTR_ctc/train_code')\n",
    "    # print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING IMAGES\n",
    "\n",
    "# Run on original images: downsize.py -> trimedges.py -> tiles.py -> filter.py (customized)\n",
    "    # Presently set to downsize large images, trim off blank edges, turn into 256x256 pixel-sized tile images, and\n",
    "    # remove non-square images (and optionally remove certain images known to not be helpful to the dataset (e.g., blank edges)).\n",
    "# Go through the results and delete:\n",
    "    # non-text images\n",
    "    # images of text not from original scribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "\n",
    "# 1. Open Anaconda terminal\n",
    "# 2. \"conda activate gendocs\"\n",
    "# 3. \"code\"\n",
    "# 4. Open terminal\n",
    "# 5. \"cd Generating-Synthetic-Handwritten-Historical-Documents\"\n",
    "# 6. Run command\n",
    "# (or you can just skip #3 and #4, get to the same path as #5, and do it from the Anaconda terminal)\n",
    "\n",
    "# Old (from colab):\n",
    "    # !/content/drive/MyDrive/Github/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/train --dataroot datasets/text2illuminated/ --cuda --target_dataset='B'\n",
    "\n",
    "# (for gendocs_test.py)   python gendocs_test.py --use_rd True\n",
    "\n",
    "# From Manuel:\n",
    "    # One example command how I ran an experimant was the following command:\n",
    "    # PyTorch-CycleGAN/train --dataroot PyTorch-CycleGAN/datasets/cropped_data/ --cuda --source_dataset EG-BG-LC --use_rd True --noise 0.05 --rd_loss_factor_B 1 --rd_pretrain_load IAM.pt\n",
    "\n",
    "# cd Generating-Synthetic-Handwritten-Historical-Documents\n",
    "# [tried] python PyTorch-CycleGAN/train --dataroot \"3HTR_ctc/data/generated/train\" --cuda True --source_dataset A --target_dataset B --use_rd True --noise 0.05 --rd_loss_factor_B 1\n",
    "# [tried] python -m PyTorch-CycleGAN.train --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/HTR_ctc/data/generated/train\" --cuda True --source_dataset A --target_dataset B --use_rd True --noise 0.05 --rd_loss_factor_B 1\n",
    "# python PyTorch-CycleGAN/train --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/HTR_ctc/data/generated/train\" --cuda --source_dataset EG-BG-LC --target_dataset B --use_rd True --noise 0.05 --rd_loss_factor_B 1\n",
    "# python PyTorch-CycleGAN/train --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --source_dataset A --target_dataset B --use_rd True --noise 0.05 --rd_loss_factor_B 1\n",
    "# python PyTorch-CycleGAN/train --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 0 --source_dataset A --target_dataset B --use_rd True --noise 0.05 --rd_loss_factor_B 1\n",
    "    # WORKS--but super-slow; test results using the one saved model were super-poor\n",
    "# python PyTorch-CycleGAN/train --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 2 --n_epochs 51 --decay_epoch 25 --batchSize 8 --source_dataset A --target_dataset B --use_rd True --noise 0.05 --rd_loss_factor_B 1\n",
    "    # didn't work (not enough ram); tried 2nd time, got batch-related error (which I couldn't understand or remedy)\n",
    "# python PyTorch-CycleGAN/train --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 2 --n_epochs 51 --decay_epoch 25 --source_dataset A --target_dataset B --use_rd True --noise 0.05 --rd_loss_factor_B 1\n",
    "    # test results using model were super-poor\n",
    "# python PyTorch-CycleGAN/train --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 2 --n_epochs 9 --decay_epoch 4 --source_dataset A --target_dataset B --use_rd True --noise 0.05 --rd_loss_factor_B 1\n",
    "    # note: when 1st epoch was starting, readout said \"Unequal\" 8 times; found in readingdiscriminator.py, but I don't understand what it means\n",
    "    # worked -- but couldn't make out whether or not it copied source text at all into target\n",
    "    # trying again with custom source text\n",
    "# python PyTorch-CycleGAN/train --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 2 --n_epochs 9 --decay_epoch 4 --source_dataset A --target_dataset B --use_rd True --rd_pretrain_load best_model_insular_.pth --noise 0.05 --rd_loss_factor_B 1\n",
    "    # using Ezek-Rev as source (A) dataset (much larger; comparable to # of original pngs used)\n",
    "    # 1st try:\n",
    "        # when 1st epoch was starting, readout said \"Unequal\" 2 times; found in readingdiscriminator.py, but I don't understand what it means\n",
    "        # got ZeroDivisionError: division by zero; adjusted train file to avoid this, but not sure whether or not it will mess things up\n",
    "    # 2nd try\n",
    "        # worked -- but no words or even legitimate letters; colors faded out\n",
    "\n",
    "# 6-25-2023\n",
    "# python PyTorch-CycleGAN/train --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 2 --n_epochs 51 --decay_epoch 25 --source_dataset A --target_dataset B --use_rd True --noise 0.05 --rd_loss_factor_B 1\n",
    "    # A results: words scrambled\n",
    "    # B results: no real words, faded, often an amorphous shape in center of image\n",
    "\n",
    "# 11-8-2023\n",
    "# python PyTorch-CycleGAN/train --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 2 --source_dataset A --target_dataset B --use_rd True --rd_loss_factor_B 1\n",
    "    # Using parameters described in paper (defaults: --n_epochs 201 --decay_epoch 100)\n",
    "    # No pretraining for reading discriminator (--rd_pretrain_load)\n",
    "    # Otherwise using parameters Manuel used in his example (above) (--use_rd True --rd_loss_factor_B 1)\n",
    "        # He also had --noise 0.05, but that is the default, so it is excluded from the command.\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# ST GALLS\n",
    "# python PyTorch-CycleGAN/train --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/saintgalldb-v1-2.0\" --cuda --n_cpu 2 --n_epochs 9 --decay_epoch 4 --source_dataset A --target_dataset saintgall --use_rd True --noise 0.05 --rd_loss_factor_B 1\n",
    "    # LOOK for source_dataset in the following to see if it needs to be changed (maybe not):\n",
    "        # PyTorch-CycleGAN/datasets.py, HTR_ctc/train_code/train_htr.py, HTR_ctc/generated_data_loader/generated_loader.py,\n",
    "        # HTR_ctc/train_code/generate_syn_diff.py, HTR_ctc/train_code/generate_pts.py\n",
    "    # LOOK to see if target_dataset needs to be changed anywhere\n",
    "    # LOOK to see if root-like paths need to be changed anywhere or if source_dataset needs to be copied into stgalls branch of datasets\n",
    "    # LOOK to see if paths with \"train\" and \"test\" need to be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "# python PyTorch-CycleGAN/test --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 1 --generator_A2B 'PyTorch-CycleGAN\\output\\91066029\\best\\netG_A2B.pth' --generator_B2A 'PyTorch-CycleGAN\\output\\91066029\\best\\netG_B2A.pth'\n",
    "    # poor\n",
    "# python PyTorch-CycleGAN/test --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 1 --generator_A2B 'PyTorch-CycleGAN\\output\\73359784\\best\\netG_A2B.pth' --generator_B2A 'PyTorch-CycleGAN\\output\\73359784\\best\\netG_B2A.pth'\n",
    "    # poor\n",
    "# python PyTorch-CycleGAN/test --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 1 --generator_A2B 'PyTorch-CycleGAN\\output\\44313040\\best\\netG_A2B.pth' --generator_B2A 'PyTorch-CycleGAN\\output\\44313040\\best\\netG_B2A.pth'\n",
    "    # I think this is the one where the csv files were ~1 MB. I had to correct & run the pdf to csv script again.\n",
    "# python PyTorch-CycleGAN/test --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 1 --generator_A2B 'PyTorch-CycleGAN\\output\\85250628\\best\\netG_A2B.pth' --generator_B2A 'PyTorch-CycleGAN\\output\\85250628\\best\\netG_B2A.pth'\n",
    "    # bad (B2A images were just colored criss-cross lines)\n",
    "# python PyTorch-CycleGAN/test --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 1 --generator_A2B 'PyTorch-CycleGAN\\output\\97993849\\netG_A2B.pth' --generator_B2A 'PyTorch-CycleGAN\\output\\97993849\\netG_B2A.pth'\n",
    "    # bad--both sets weird (not even close)\n",
    "# python PyTorch-CycleGAN/test --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 1 --generator_A2B 'PyTorch-CycleGAN\\output\\97993849\\2\\netG_A2B.pth' --generator_B2A 'PyTorch-CycleGAN\\output\\97993849\\2\\netG_B2A.pth'\n",
    "    # B2A--bad (just colored criss-cross lines); A2B--poor (no legible words)\n",
    "# python PyTorch-CycleGAN/test --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 1 --generator_A2B 'PyTorch-CycleGAN\\output\\97993849\\5\\netG_A2B.pth' --generator_B2A 'PyTorch-CycleGAN\\output\\97993849\\5\\netG_B2A.pth'\n",
    "    # B2A--bad; A2B--poor (no legible words)\n",
    "# python PyTorch-CycleGAN/test --dataroot \"C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells\" --cuda --n_cpu 1 --generator_A2B 'PyTorch-CycleGAN\\output\\14990599\\netG_A2B.pth' --generator_B2A 'PyTorch-CycleGAN\\output\\14990599\\netG_B2A.pth'\n",
    "    # 5: B2A--fair (word-like, but not words; overabundance of same few letters (s, a, r, e.g.)); A2B--gave lots of blank vellum, then gave original test/B images\n",
    "    # 2: B2A--poor (overlapping lines, not words, background speckled with colors); A2B--poor (no words, varying distances between lines, all colors faded, some non-letters)\n",
    "    # 14990599: B2A--bad (colored criss-cross lines); A2B--poor (no words, all colors faded, the same colored-in indistinct larger letter showed up on numerous images)\n",
    "# (4-20-2023)\n",
    "# python PyTorch-CycleGAN/test --dataroot 'C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells' --cuda --n_cpu 1 --generator_A2B 'PyTorch-CycleGAN/output/98059012/5/netG_A2B.pth' --generator_B2A 'PyTorch-CycleGAN/output/98059012/5/netG_B2A.pth'\n",
    "    # 98059012/5:\n",
    "\n",
    "# (6-28-2023)\n",
    "# python PyTorch-CycleGAN/test --dataroot 'C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells' --cuda --n_cpu 1 --generator_A2B 'PyTorch-CycleGAN/output/92559296/netG_A2B.pth' --generator_B2A 'PyTorch-CycleGAN/output/92559296/netG_B2A.pth'\n",
    "    # just as bad as prior tests, despite significant increase in epochs (51; previously 9)\n",
    "# python PyTorch-CycleGAN/test --dataroot 'C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells' --cuda --n_cpu 1 --generator_A2B 'PyTorch-CycleGAN/output/92559296/40/netG_A2B.pth' --generator_B2A 'PyTorch-CycleGAN/output/92559296/40/netG_B2A.pth'\n",
    "    # just as bad\n",
    "\n",
    "# (11-18-2023)\n",
    "# python PyTorch-CycleGAN/test --dataroot 'C:/Users/scott/desktop/manuscriptproject/code/Generating-Synthetic-Handwritten-Historical-Documents/PyTorch-CycleGAN/datasets/text2kells' --cuda --n_cpu 1 --generator_A2B 'PyTorch-CycleGAN/output/98490757/netG_A2B.pth' --generator_B2A 'PyTorch-CycleGAN/output/98490757/netG_B2A.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRETRAINING FOR READING DISCRIMINATOR\n",
    "\n",
    "# model after St. Gall dataset\n",
    "# trying docExtractor (using Ubuntu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TROUBLESHOOTING\n",
    "\n",
    "# need to reshape target images to all be same\n",
    "\n",
    "# lower number of workers--THIS SEEMS TO HAVE SOLVED THE PROBLEM FOR NOW (tried 0 successfully; will experiment with higher #s)\n",
    "# change list of target images to numpy array?\n",
    "    # try something like this in datasets.py: x = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "# use del on certain variables (del when done with a tensor)?\n",
    "    # tensors holding loss and output can live beyond the training loop. In order to truly free up the space held by these tensors, we use del keyword.\n",
    "    # Example: del out, loss\n",
    "# use torch.cuda.empty_cache() at end of code?\n",
    "# whenever you want to execute a piece of code that doesn't need to be backpropagated, put it inside a torch.no_grad() context manager\n",
    "    # with torch.no_grad()\n",
    "        # # your code\n",
    "# enable cudnn benchmark (at top of code)?\n",
    "    # torch.backends.cudnn.benchmark = True\n",
    "    # torch.backends.cudnn.enabled = True\n",
    "# watch memory consumption using pytorch profiler?\n",
    "    # from torch.profiler import profile, record_function, ProfilerActivity\n",
    "    # with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n",
    "        # model(inputs)\n",
    "    # print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
    "\n",
    "# can use this to measure gpu usage:\n",
    "    # from GPUtil import showUtilization as gpu_usage\n",
    "    # print(\"GPU Usage after deleting the Tensors\")\n",
    "    # gpu_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gendocs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4ebd95a229f19e974b5b883f58d60aff9b45a532b0c6328db92254da2014d74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
